{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28d98df-59f8-4d90-a7dc-977da1a213be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: speechrecognition in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (3.14.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from speechrecognition) (4.12.2)\n",
      "Requirement already satisfied: transformers in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (4.51.0)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: torch in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: soundfile in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from soundfile) (2.0.2)\n",
      "Requirement already satisfied: pycparser in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: librosa in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (4.6.2)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (0.30.1)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting matplotlib~=3.0 (from gradio)\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (2.0.2)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.16-cp39-cp39-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Collecting pillow<11.0,>=8.0 (from gradio)\n",
      "  Downloading pillow-10.4.0-cp39-cp39-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.11.4-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio) (2.3.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2025.3.2)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
      "  Downloading websockets-12.0-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: certifi in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.67.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.21.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
      "  Downloading fonttools-4.57.0-cp39-cp39-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.33.1-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.1 MB 578.7 kB/s eta 0:00:31\n",
      "   - -------------------------------------- 0.5/18.1 MB 578.7 kB/s eta 0:00:31\n",
      "   - -------------------------------------- 0.5/18.1 MB 578.7 kB/s eta 0:00:31\n",
      "   - -------------------------------------- 0.8/18.1 MB 516.0 kB/s eta 0:00:34\n",
      "   - -------------------------------------- 0.8/18.1 MB 516.0 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 1.0/18.1 MB 503.2 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 1.0/18.1 MB 503.2 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 1.0/18.1 MB 503.2 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 1.3/18.1 MB 493.4 kB/s eta 0:00:34\n",
      "   -- ------------------------------------- 1.3/18.1 MB 493.4 kB/s eta 0:00:34\n",
      "   --- ------------------------------------ 1.6/18.1 MB 502.4 kB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 556.2 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 556.2 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 584.2 kB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 584.2 kB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 2.4/18.1 MB 586.1 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 2.4/18.1 MB 586.1 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 2.6/18.1 MB 592.2 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 2.6/18.1 MB 592.2 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 2.9/18.1 MB 597.0 kB/s eta 0:00:26\n",
      "   ------ --------------------------------- 2.9/18.1 MB 597.0 kB/s eta 0:00:26\n",
      "   ------ --------------------------------- 3.1/18.1 MB 603.1 kB/s eta 0:00:25\n",
      "   ------- -------------------------------- 3.4/18.1 MB 610.1 kB/s eta 0:00:25\n",
      "   ------- -------------------------------- 3.4/18.1 MB 610.1 kB/s eta 0:00:25\n",
      "   ------- -------------------------------- 3.4/18.1 MB 610.1 kB/s eta 0:00:25\n",
      "   -------- ------------------------------- 3.7/18.1 MB 609.2 kB/s eta 0:00:24\n",
      "   -------- ------------------------------- 3.9/18.1 MB 624.7 kB/s eta 0:00:23\n",
      "   -------- ------------------------------- 3.9/18.1 MB 624.7 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 4.2/18.1 MB 622.9 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 4.2/18.1 MB 622.9 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 4.2/18.1 MB 622.9 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 4.5/18.1 MB 610.1 kB/s eta 0:00:23\n",
      "   --------- ------------------------------ 4.5/18.1 MB 610.1 kB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 4.7/18.1 MB 612.1 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 4.7/18.1 MB 612.1 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 5.0/18.1 MB 603.9 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 5.0/18.1 MB 603.9 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 5.2/18.1 MB 606.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 5.2/18.1 MB 606.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 5.2/18.1 MB 606.0 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 5.5/18.1 MB 603.5 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 5.8/18.1 MB 607.4 kB/s eta 0:00:21\n",
      "   ------------ --------------------------- 5.8/18.1 MB 607.4 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 6.0/18.1 MB 606.0 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 6.0/18.1 MB 606.0 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 6.3/18.1 MB 606.7 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 6.3/18.1 MB 606.7 kB/s eta 0:00:20\n",
      "   ------------- -------------------------- 6.3/18.1 MB 606.7 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 6.6/18.1 MB 605.5 kB/s eta 0:00:20\n",
      "   --------------- ------------------------ 6.8/18.1 MB 608.7 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 6.8/18.1 MB 608.7 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 6.8/18.1 MB 608.7 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 7.1/18.1 MB 607.5 kB/s eta 0:00:19\n",
      "   --------------- ------------------------ 7.1/18.1 MB 607.5 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 7.3/18.1 MB 604.0 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 7.3/18.1 MB 604.0 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 7.3/18.1 MB 604.0 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 7.6/18.1 MB 597.7 kB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 7.6/18.1 MB 597.7 kB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 7.9/18.1 MB 594.8 kB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 7.9/18.1 MB 594.8 kB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 8.1/18.1 MB 597.0 kB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 8.1/18.1 MB 597.0 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 8.4/18.1 MB 597.1 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 8.4/18.1 MB 597.1 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 8.7/18.1 MB 593.9 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 8.7/18.1 MB 593.9 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 8.9/18.1 MB 601.1 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 9.2/18.1 MB 606.2 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 9.2/18.1 MB 606.2 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 9.4/18.1 MB 612.9 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 9.7/18.1 MB 620.1 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 10.0/18.1 MB 626.4 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 10.2/18.1 MB 631.8 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 10.2/18.1 MB 631.8 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 10.5/18.1 MB 637.7 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 10.7/18.1 MB 643.4 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 11.0/18.1 MB 650.8 kB/s eta 0:00:11\n",
      "   ------------------------ --------------- 11.3/18.1 MB 656.7 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.1 MB 661.9 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 11.8/18.1 MB 667.5 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 11.8/18.1 MB 667.5 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 12.1/18.1 MB 673.5 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 12.3/18.1 MB 678.2 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 12.6/18.1 MB 682.7 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 12.8/18.1 MB 688.3 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 13.1/18.1 MB 693.2 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 13.4/18.1 MB 697.9 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 13.4/18.1 MB 697.9 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 13.6/18.1 MB 703.6 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 14.2/18.1 MB 715.4 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 14.2/18.1 MB 715.4 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 14.4/18.1 MB 719.0 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 14.7/18.1 MB 722.6 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 14.9/18.1 MB 727.2 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 15.2/18.1 MB 732.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 15.5/18.1 MB 737.8 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 15.5/18.1 MB 737.8 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 15.7/18.1 MB 739.8 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 16.0/18.1 MB 744.6 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 16.3/18.1 MB 748.1 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 16.5/18.1 MB 750.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 16.8/18.1 MB 753.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 17.0/18.1 MB 758.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.3/18.1 MB 762.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.3/18.1 MB 762.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.6/18.1 MB 763.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.1 MB 767.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 768.5 kB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Downloading matplotlib-3.9.4-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.8 MB 1.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.8 MB 1.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 1.0 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 1.0 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.3/7.8 MB 945.5 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.3/7.8 MB 945.5 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.6/7.8 MB 892.9 kB/s eta 0:00:08\n",
      "   -------- ------------------------------- 1.6/7.8 MB 892.9 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 1.8/7.8 MB 832.2 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.1/7.8 MB 810.2 kB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.1/7.8 MB 810.2 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 2.4/7.8 MB 818.6 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 2.6/7.8 MB 816.4 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 2.6/7.8 MB 816.4 kB/s eta 0:00:07\n",
      "   -------------- ------------------------- 2.9/7.8 MB 834.9 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.1/7.8 MB 850.6 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 3.4/7.8 MB 864.2 kB/s eta 0:00:06\n",
      "   ------------------ --------------------- 3.7/7.8 MB 876.1 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 3.9/7.8 MB 886.5 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 3.9/7.8 MB 886.5 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 4.2/7.8 MB 876.9 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.5/7.8 MB 880.2 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 4.7/7.8 MB 883.2 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 4.7/7.8 MB 883.2 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 5.0/7.8 MB 870.4 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 5.2/7.8 MB 880.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.2/7.8 MB 880.6 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.5/7.8 MB 873.8 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.5/7.8 MB 873.8 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 5.8/7.8 MB 869.9 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.0/7.8 MB 866.5 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.0/7.8 MB 866.5 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 6.3/7.8 MB 865.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.6/7.8 MB 862.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.6/7.8 MB 862.3 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.8/7.8 MB 847.4 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.8/7.8 MB 847.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 7.1/7.8 MB 848.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.3/7.8 MB 857.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.6/7.8 MB 863.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 856.5 kB/s eta 0:00:00\n",
      "Downloading orjson-3.10.16-cp39-cp39-win_amd64.whl (133 kB)\n",
      "Downloading pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 986.7 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.3/2.6 MB 958.5 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.6/2.6 MB 987.0 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.6 MB 987.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 949.2 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 954.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 938.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 938.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 873.3 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 853.0 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 853.0 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/2.0 MB 853.0 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.3/2.0 MB 745.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 749.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 749.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 774.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 773.1 kB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.4-py3-none-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.4 MB 1.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/11.4 MB 1.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.4 MB 1.0 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/11.4 MB 1.0 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/11.4 MB 1.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.4 MB 1.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.4 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.4 MB 1.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.4 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.4 MB 952.0 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.4/11.4 MB 952.0 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.6/11.4 MB 898.8 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.9/11.4 MB 902.1 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.9/11.4 MB 902.1 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 3.1/11.4 MB 900.3 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 3.4/11.4 MB 911.0 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.7/11.4 MB 912.7 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.7/11.4 MB 912.7 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.9/11.4 MB 906.8 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 4.2/11.4 MB 905.2 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.2/11.4 MB 905.2 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.5/11.4 MB 900.8 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.5/11.4 MB 900.8 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.7/11.4 MB 883.0 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.7/11.4 MB 883.0 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.7/11.4 MB 883.0 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 5.0/11.4 MB 816.2 kB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 5.0/11.4 MB 816.2 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 5.2/11.4 MB 799.0 kB/s eta 0:00:08\n",
      "   ------------------ --------------------- 5.2/11.4 MB 799.0 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.5/11.4 MB 787.7 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.5/11.4 MB 787.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.8/11.4 MB 784.8 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 5.8/11.4 MB 784.8 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 6.0/11.4 MB 765.8 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 6.0/11.4 MB 765.8 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 6.0/11.4 MB 765.8 kB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 6.3/11.4 MB 742.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.3/11.4 MB 742.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.3/11.4 MB 742.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.6/11.4 MB 733.4 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.6/11.4 MB 733.4 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 725.7 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 6.8/11.4 MB 725.7 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 7.1/11.4 MB 710.4 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 7.1/11.4 MB 710.4 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 7.1/11.4 MB 710.4 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 7.3/11.4 MB 695.8 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.3/11.4 MB 695.8 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 7.3/11.4 MB 695.8 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 7.6/11.4 MB 686.8 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 7.6/11.4 MB 686.8 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 7.9/11.4 MB 676.7 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 7.9/11.4 MB 676.7 kB/s eta 0:00:06\n",
      "   --------------------------- ------------ 7.9/11.4 MB 676.7 kB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 666.6 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 666.6 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.4/11.4 MB 661.7 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 8.4/11.4 MB 661.7 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.7/11.4 MB 663.7 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.7/11.4 MB 663.7 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 8.9/11.4 MB 661.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.9/11.4 MB 661.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.9/11.4 MB 661.5 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.2/11.4 MB 649.7 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.2/11.4 MB 649.7 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 9.2/11.4 MB 649.7 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.4/11.4 MB 641.7 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 9.4/11.4 MB 641.7 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.7/11.4 MB 641.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 9.7/11.4 MB 641.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 9.7/11.4 MB 641.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.0/11.4 MB 632.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.0/11.4 MB 632.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.0/11.4 MB 632.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 10.0/11.4 MB 632.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 10.2/11.4 MB 617.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.4 MB 617.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.5/11.4 MB 618.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.7/11.4 MB 623.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.7/11.4 MB 623.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 11.0/11.4 MB 629.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.4 MB 635.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 636.4 kB/s eta 0:00:00\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 873.8 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 873.8 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 873.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 774.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 782.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 796.7 kB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading websockets-12.0-cp39-cp39-win_amd64.whl (124 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, typing-inspection, tomlkit, shellingham, semantic-version, ruff, python-multipart, pyparsing, pydantic-core, pillow, orjson, mdurl, markupsafe, kiwisolver, importlib-resources, fonttools, ffmpy, cycler, contourpy, click, annotated-types, aiofiles, uvicorn, starlette, pydantic, matplotlib, markdown-it-py, rich, gradio-client, fastapi, typer, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 click-8.1.8 contourpy-1.3.0 cycler-0.12.1 fastapi-0.115.12 ffmpy-0.5.0 fonttools-4.57.0 gradio-4.44.1 gradio-client-1.3.0 importlib-resources-6.5.2 kiwisolver-1.4.7 markdown-it-py-3.0.0 markupsafe-2.1.5 matplotlib-3.9.4 mdurl-0.1.2 orjson-3.10.16 pillow-10.4.0 pydantic-2.11.2 pydantic-core-2.33.1 pydub-0.25.1 pyparsing-3.2.3 python-multipart-0.0.20 rich-14.0.0 ruff-0.11.4 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.1 tomlkit-0.12.0 typer-0.15.2 typing-inspection-0.4.0 uvicorn-0.34.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install speechrecognition\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "!pip install gradio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67867264-a1e8-44e9-80bc-39b543637fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref                                                       title                                                   size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
      "--------------------------------------------------------  -----------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
      "datafiniti/grammar-and-online-product-reviews             Grammar and Online Product Reviews                   9383592  2018-02-15 17:20:27                  5175        104  0.7058824        \n",
      "dariocioni/c4200m                                         C4 200M Grammar Error Correction dataset         15601869562  2023-04-18 16:46:11                  1909         44  1.0              \n",
      "satishgunjal/grammar-correction                           Grammar Correction                                     63861  2023-12-19 06:39:41.163000            780         10  0.9411765        \n",
      "harshildarji/reber                                        Reber Grammar                                         259811  2022-01-22 15:59:27.143000             64          4  0.9411765        \n",
      "sunnysai12345/news-summary                                NEWS SUMMARY                                        20718321  2019-11-13 06:29:30.303000          20264        217  0.7058824        \n",
      "mahakhan44/urdu-grammar                                   urdu-grammar                                            4184  2025-01-13 11:52:35                     7          1  0.9375           \n",
      "rareloto/naver-dictionary-conversation-of-the-day         Korean - English Parallel Corpus                      332074  2020-08-19 14:41:38.993000            851         18  1.0              \n",
      "nltkdata/grammars                                         Grammars                                              672488  2017-08-21 02:04:53.987000             99          5  0.6875           \n",
      "pranav082001/grammaratical-error-correction-dataset       Grammaratical Error Correction Dataset                133617  2021-10-03 12:03:02.303000            284          7  0.5294118        \n",
      "dardodel/4k-mixtral87b-crafted-essays-for-detect-ai-comp  4k Mixtral87b Crafted Essays for Detect AI Comp      5598351  2024-01-08 01:58:53.277000            159         25  0.7058824        \n",
      "bobirakova/grammar                                        grammar                                               180131  2020-04-15 07:16:44.727000             33          1  0.1875           \n",
      "javiersastre/severe-grammar                               Severe grammar                                       1243807  2020-06-10 20:55:23.477000             14          1  0.3125           \n",
      "nezahatkk/grammar-correction-dataset-for-fine-tuning      Grammar Correction Dataset for Fine-Tuning            180270  2025-01-28 15:29:23                    20          3  0.88235295       \n",
      "akarshsinghh/list-of-sentences                            List of Sentences                                      98497  2021-12-04 12:04:57.857000            257         11  0.9375           \n",
      "javiersastre/libgrapenlp                                  libgrapenlp-2.8.0                                     767439  2020-04-09 09:50:25.407000             18          1  0.6875           \n",
      "a0155991rliwei/c4-200m                                    C4_200M                                          20746659480  2021-11-13 10:30:36.597000           1004         11  0.9375           \n",
      "b'maramalhinai/arabic-grammar-sentence-parsing              Arabic grammar sentence parsing \\xd8\\xa5\\xd8\\xb9\\xd8\\xb1\\xd8\\xa7\\xd8\\xa8                  34514  2024-11-24 14:42:07                     7          1  0.75             '\n",
      "defdet/grammar-corrected-persuade-10k                     grammar-corrected-persuade-10k                       7515561  2023-11-03 13:12:23.303000             26          2  0.1764706        \n",
      "miguelcorraljr/doctoralia-brasil                          Doctoralia Brasil                                    7391145  2022-11-03 15:04:58                   410         13  1.0              \n",
      "davidspencer/persuade-rubric-holistic-essay-scoring       PERSUADE Rubric: Holistic Essay Scoring                80459  2024-04-14 16:04:22.487000             55          8  0.875            \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12c3cdf-13b7-4c48-9468-94a82b6b0465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/satishgunjal/grammar-correction\n",
      "License(s): apache-2.0\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d satishgunjal/grammar-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8faa2f19-1f7e-4f1a-8b1e-a77bbd10b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"grammar-correction.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"grammar_dataset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a2f0310-5879-42cc-b4a4-4ecad6b954f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number         Error Type              Ungrammatical Statement  \\\n",
       "0              1  Verb Tense Errors        I goes to the store everyday.   \n",
       "1              2  Verb Tense Errors  They was playing soccer last night.   \n",
       "2              3  Verb Tense Errors     She have completed her homework.   \n",
       "3              4  Verb Tense Errors            He don't know the answer.   \n",
       "4              5  Verb Tense Errors            The sun rise in the east.   \n",
       "\n",
       "                       Standard English  \n",
       "0           I go to the store everyday.  \n",
       "1  They were playing soccer last night.  \n",
       "2       She has completed her homework.  \n",
       "3           He doesn't know the answer.  \n",
       "4            The sun rises in the east.  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"grammar_dataset/Grammar_Correction.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6c50d3-5e06-422a-9679-daee9fe8c22d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2018 entries, 0 to 2017\n",
      "Data columns (total 4 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Serial Number            2018 non-null   int64 \n",
      " 1   Error Type               2018 non-null   object\n",
      " 2   Ungrammatical Statement  2018 non-null   object\n",
      " 3   Standard English         2018 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 63.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>Ungrammatical Statement</th>\n",
       "      <th>Standard English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>1209</td>\n",
       "      <td>Quantifier Errors</td>\n",
       "      <td>All of the students in this class are attentive.</td>\n",
       "      <td>All the students in this class are attentive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1197</td>\n",
       "      <td>Quantifier Errors</td>\n",
       "      <td>All of the paintings in this gallery are moder...</td>\n",
       "      <td>All the paintings in this gallery are modern art.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2009</td>\n",
       "      <td>Lack of Parallelism in Lists or Series</td>\n",
       "      <td>The training program focuses on skill developm...</td>\n",
       "      <td>The training program focuses on skill developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>474</td>\n",
       "      <td>Sentence Structure Errors</td>\n",
       "      <td>They visited their grandparents on the weekend.</td>\n",
       "      <td>They visited their grandparents on the weekend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>754</td>\n",
       "      <td>Run-on Sentences</td>\n",
       "      <td>He saw the advertisement he decided to apply.</td>\n",
       "      <td>He saw the advertisement, and he decided to ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Serial Number                              Error Type  \\\n",
       "1208           1209                       Quantifier Errors   \n",
       "1196           1197                       Quantifier Errors   \n",
       "2008           2009  Lack of Parallelism in Lists or Series   \n",
       "473             474               Sentence Structure Errors   \n",
       "753             754                        Run-on Sentences   \n",
       "\n",
       "                                Ungrammatical Statement  \\\n",
       "1208   All of the students in this class are attentive.   \n",
       "1196  All of the paintings in this gallery are moder...   \n",
       "2008  The training program focuses on skill developm...   \n",
       "473     They visited their grandparents on the weekend.   \n",
       "753       He saw the advertisement he decided to apply.   \n",
       "\n",
       "                                       Standard English  \n",
       "1208      All the students in this class are attentive.  \n",
       "1196  All the paintings in this gallery are modern art.  \n",
       "2008  The training program focuses on skill developm...  \n",
       "473     They visited their grandparents on the weekend.  \n",
       "753   He saw the advertisement, and he decided to ap...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3892f26b-3382-4fc8-b8e1-c4b473142946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>Error Type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>I goes to the store everyday.</td>\n",
       "      <td>I go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>She have completed her homework.</td>\n",
       "      <td>She has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>He don't know the answer.</td>\n",
       "      <td>He doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>The sun rise in the east.</td>\n",
       "      <td>The sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial Number         Error Type                            incorrect  \\\n",
       "0              1  Verb Tense Errors        I goes to the store everyday.   \n",
       "1              2  Verb Tense Errors  They was playing soccer last night.   \n",
       "2              3  Verb Tense Errors     She have completed her homework.   \n",
       "3              4  Verb Tense Errors            He don't know the answer.   \n",
       "4              5  Verb Tense Errors            The sun rise in the east.   \n",
       "\n",
       "                                correct  \n",
       "0           I go to the store everyday.  \n",
       "1  They were playing soccer last night.  \n",
       "2       She has completed her homework.  \n",
       "3           He doesn't know the answer.  \n",
       "4            The sun rises in the east.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'Ungrammatical Statement': 'incorrect', 'Standard English': 'correct'}) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74978f14-2077-4fec-90f9-86d4e52dda7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial number</th>\n",
       "      <th>error type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>1363</td>\n",
       "      <td>Ambiguity</td>\n",
       "      <td>The car was drove by him.</td>\n",
       "      <td>The car was driven by him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>Mixed Metaphors/Idioms</td>\n",
       "      <td>39. You can catch more flies with honey than w...</td>\n",
       "      <td>39. You can catch more flies with honey than w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>407</td>\n",
       "      <td>Sentence Structure Errors</td>\n",
       "      <td>The childrens had a lot of fun at the playground.</td>\n",
       "      <td>The children had a lot of fun at the playground.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>803</td>\n",
       "      <td>Sentence Fragments</td>\n",
       "      <td>The computer, slow, needs an upgrade.</td>\n",
       "      <td>The computer is slow and needs an upgrade.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>They was playing soccer last night.</td>\n",
       "      <td>They were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>1820</td>\n",
       "      <td>Relative Clause Errors</td>\n",
       "      <td>The cake I ate it for dessert was delicious.</td>\n",
       "      <td>The cake I ate for dessert was delicious.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      serial number                 error type  \\\n",
       "1362           1363                  Ambiguity   \n",
       "876             877     Mixed Metaphors/Idioms   \n",
       "406             407  Sentence Structure Errors   \n",
       "802             803         Sentence Fragments   \n",
       "1                 2          Verb Tense Errors   \n",
       "1819           1820     Relative Clause Errors   \n",
       "\n",
       "                                              incorrect  \\\n",
       "1362                          The car was drove by him.   \n",
       "876   39. You can catch more flies with honey than w...   \n",
       "406   The childrens had a lot of fun at the playground.   \n",
       "802               The computer, slow, needs an upgrade.   \n",
       "1                   They was playing soccer last night.   \n",
       "1819       The cake I ate it for dessert was delicious.   \n",
       "\n",
       "                                                correct  \n",
       "1362                         The car was driven by him.  \n",
       "876   39. You can catch more flies with honey than w...  \n",
       "406    The children had a lot of fun at the playground.  \n",
       "802          The computer is slow and needs an upgrade.  \n",
       "1                  They were playing soccer last night.  \n",
       "1819          The cake I ate for dessert was delicious.  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2e9072a-711a-4740-be04-f65298228c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial number    0\n",
       "error type       0\n",
       "incorrect        0\n",
       "correct          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4fa684d-ba0a-4697-acc4-5dc44cb5cba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b2352bf-56f8-4346-8428-4fb3a93323f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial number</th>\n",
       "      <th>error type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>i goes to the store everyday.</td>\n",
       "      <td>i go to the store everyday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>they was playing soccer last night.</td>\n",
       "      <td>they were playing soccer last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>she have completed her homework.</td>\n",
       "      <td>she has completed her homework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>he don't know the answer.</td>\n",
       "      <td>he doesn't know the answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Verb Tense Errors</td>\n",
       "      <td>the sun rise in the east.</td>\n",
       "      <td>the sun rises in the east.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial number         error type                            incorrect  \\\n",
       "0              1  Verb Tense Errors        i goes to the store everyday.   \n",
       "1              2  Verb Tense Errors  they was playing soccer last night.   \n",
       "2              3  Verb Tense Errors     she have completed her homework.   \n",
       "3              4  Verb Tense Errors            he don't know the answer.   \n",
       "4              5  Verb Tense Errors            the sun rise in the east.   \n",
       "\n",
       "                                correct  \n",
       "0           i go to the store everyday.  \n",
       "1  they were playing soccer last night.  \n",
       "2       she has completed her homework.  \n",
       "3           he doesn't know the answer.  \n",
       "4            the sun rises in the east.  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).strip()\n",
    "    text = \" \".join(text.split())  # remove multiple spaces\n",
    "    return text.lower()  # optional: only if you want case insensitivity\n",
    "\n",
    "df[\"incorrect\"] = df[\"incorrect\"].apply(clean_text)\n",
    "df[\"correct\"] = df[\"correct\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44130f7f-7b02-46fc-8fda-9d4f750b2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {\"input\": \"grammar: \" + row[\"incorrect\"], \"output\": row[\"correct\"]}\n",
    "    for _, row in df.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1614a17c-49e1-414a-984a-dabea2d44962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed fsspec-2024.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaf86443-8469-4262-8c44-e89533a44614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 1816\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 202\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(train_data)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b99b6d1-6b7a-462c-9d7e-9b3fcebda311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad7ad05-f80f-4aa5-8b42-4e57c1fc8518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fa892c7-e55f-4e7f-8595-b48eadeb43e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: huggingface_hub in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8128351-6ac1-483c-bdcf-34e60cbec3b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d46199367334accb57c1a2a2b2602fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c55a3e82f4337ae678e8629d65d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(batch):\n",
    "    input_enc = tokenizer(batch['input'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    target_enc = tokenizer(batch['output'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    input_enc['labels'] = target_enc['input_ids']\n",
    "    return input_enc\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc2fcab1-b048-426a-92b2-2cbcb686ccc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting colorama (from tqdm>=4.27->transformers)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, colorama, charset-normalizer, certifi, tqdm, requests, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.1\n",
      "    Uninstalling typing_extensions-4.13.1:\n",
      "      Successfully uninstalled typing_extensions-4.13.1\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.1\n",
      "    Uninstalling charset-normalizer-3.4.1:\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.30.1\n",
      "    Uninstalling huggingface-hub-0.30.1:\n",
      "      Successfully uninstalled huggingface-hub-0.30.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.0\n",
      "    Uninstalling transformers-4.51.0:\n",
      "      Successfully uninstalled transformers-4.51.0\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 colorama-0.4.6 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 idna-3.10 numpy-2.0.2 packaging-24.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.0 typing-extensions-4.13.1 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22ec8e6e-1866-48d0-b14c-1a089c94473a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ee74435-1eb9-475b-8ce6-4846325b08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfe6779a-c365-4d6e-8d8a-042c67d13788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='681' max='681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [681/681 1:01:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.230476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.177116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.166850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=681, training_loss=0.7794576070425969, metrics={'train_runtime': 3673.0035, 'train_samples_per_second': 1.483, 'train_steps_per_second': 0.185, 'total_flos': 184335533604864.0, 'train_loss': 0.7794576070425969, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5442cac9-5cda-4d95-a242-ba7b68f12c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16685020923614502, 'eval_runtime': 31.5487, 'eval_samples_per_second': 6.403, 'eval_steps_per_second': 0.824, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ae4b8-92ea-4c7c-8af6-5731a4225311",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./grammar_model\")\n",
    "tokenizer.save_pretrained(\"./grammar_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb7e020c-056f-4be2-874e-4998d3ce6d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (3.14.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp39-cp39-win_amd64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from SpeechRecognition) (4.13.1)\n",
      "Downloading PyAudio-0.2.14-cp39-cp39-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition pyaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59df1089-078b-491b-bd9e-ac2c8487c5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (4.51.0)\n",
      "Requirement already satisfied: torch in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: speechrecognition in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (3.14.2)\n",
      "Collecting language-tool-python\n",
      "  Downloading language_tool_python-2.9.2-py3-none-any.whl.metadata (54 kB)\n",
      "Requirement already satisfied: filelock in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from language-tool-python) (5.9.0)\n",
      "Collecting toml (from language-tool-python)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: colorama in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\priya\\anaconda3\\envs\\grammar_voice\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading language_tool_python-2.9.2-py3-none-any.whl (54 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: toml, language-tool-python\n",
      "Successfully installed language-tool-python-2.9.2 toml-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch speechrecognition language-tool-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71135f38-2f92-45b6-80f5-53543afaa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Manually set JAVA path for language_tool_python\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Users\\priya\\AppData\\Local\\Programs\\Eclipse Adoptium\\jdk-21.0.6.7-hotspot\"\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\priya\\AppData\\Local\\Programs\\Eclipse Adoptium\\jdk-21.0.6.7-hotspot\\bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0da74e1-0f84-40ad-9222-052ebde6ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Speak something...\n",
      "🗣 You said: I live in Jamshedpur\n",
      "✅ Corrected Text: I live in Jamshedpur.\n",
      "📊 Grammar Score: 10/10 (Perfect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import speech_recognition as sr\n",
    "import language_tool_python\n",
    "\n",
    "# Load T5 model for grammar correction\n",
    "model_path = \"./grammar_model\"  # or use \"prithivida/grammar_error_correcter_v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Initialize LanguageTool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Initialize recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Record voice\n",
    "with sr.Microphone() as source:\n",
    "    print(\"🎤 Speak something...\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "try:\n",
    "    # Step 1: Transcribe voice\n",
    "    text = r.recognize_google(audio)\n",
    "    print(\"🗣 You said:\", text)\n",
    "\n",
    "    # Step 2: Check grammar errors before correction\n",
    "    errors_before = len(tool.check(text))\n",
    "\n",
    "    # Step 3: Correct grammar using T5\n",
    "    input_ids = tokenizer.encode(\"fix: \" + text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    corrected = corrected.replace(\"fix:\", \"\").strip()\n",
    "\n",
    "    print(\"✅ Corrected Text:\", corrected)\n",
    "\n",
    "    # Step 4: Check grammar errors after correction\n",
    "    errors_after = len(tool.check(corrected))\n",
    "\n",
    "    # Step 5: Score logic (updated)\n",
    "    if errors_before == 0 and errors_after == 0:\n",
    "        score = \"10/10 (Perfect)\"\n",
    "    elif errors_before == 0 and errors_after > 0:\n",
    "        score = \"1/10 (Correction made grammar worse)\"\n",
    "    elif errors_before > 0:\n",
    "        improvement = errors_before - errors_after\n",
    "        if improvement > 0:\n",
    "            percent = int((improvement / errors_before) * 10)\n",
    "            percent = min(10, max(1, percent))  # Clamp to 1–10\n",
    "            score = f\"{percent}/10 (Improved)\"\n",
    "        else:\n",
    "            score = \"1/10 (No improvement)\"\n",
    "    else:\n",
    "        score = \"1/10 (Unclear grammar state)\"\n",
    "\n",
    "    print(\"📊 Grammar Score:\", score)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"❌ Could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"⚠️ Error with Speech Recognition: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1564b73-980c-4a47-afe6-8c48bb238616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
